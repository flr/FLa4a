\documentclass[a4paper,english,10pt]{article}
\usepackage{a4a}
%\VignetteIndexEntry{Natural Mortality}
%\VignetteEngine{knitr::knitr}
\begin{document}

\title{Assessment for All initiative(a4a) \\ Natural Mortality Modelling}

\input{authors}

\maketitle
\tableofcontents
\newpage

%% ======================================
%% Call child document with libs and data
<<libs, child='libsanddata.sub'>>=
@

\section{Natural mortality}\label{sec:M}

In the \aFa natural mortality is dealt with as an external parameter to the stock assessment model. The rationale to modelling natural mortality is similar to that of growth: one should be able to grab information from a range of sources and feed it into the assessment.

The mechanism used by \aFa is to build an interface that makes it transparent, flexible and hopefully easy to explore different options. In relation to natural mortality it means that the analyst should be able to use distinct models like Gislasson's, Charnov's, Pauly's, etc in a coherent framework making it possible to compare the outcomes of the assessment. 

Within the \aFa framework, the general method for inserting natural mortality in the stock assessment is to:

\begin{itemize}
    \item Create an object of class \class{a4aM} which holds the natural mortality model and parameters.
    \item Add uncertainty to the parameters in the \class{a4aM} object.
    \item Apply the \code{m()} method to the \class{a4aM} object to create an age or length based \class{FLQuant} object of the required dimensions.
\end{itemize}

The resulting \class{FLQuant} object can then be directly inserted into an \class {FLStock} object to be used for the assessment.   

In this section we go through each of the steps in detail using a variety of different models.

\section{\code{a4aM} - The M class}

Natural mortality is implemented in a class named \class{a4aM}. This class is made up of three objects of the class \class{FLModelSim}. Each object is a model that represents one effect: an age or length effect, a scaling (level) effect and a time trend, named \code{shape}, \code{level} and \code{trend}, respectively. The impact of the models is multiplicative, i.e. the overal natural mortality is given by \class{shape} x  \class{level} x \class{trend}. Check the help files for more information.

<<showClass_a4aM>>=
showClass("a4aM")
@

The \class{a4aM} constructor requires that the models and parameters are provided. The default method will build each of these models as a constant value of 1.

As a simple example, the usual "0.2" guessestimate could be set up by setting the \code{level} model to have a single parameter with a fixed value, while the other two models, \class{shape} and \class{trend}, have a default value of 1 (meaning that they have no effect).

<<m_02>>=
mod02 <- FLModelSim(model=~a, params=FLPar(a=0.2))
m1 <- a4aM(level=mod02)
m1
@

More interesting natural mortality shapes can be set up using biological knowledge. The following example uses an exponential decay over ages (implying that the resulting \class{FLQuant} generated by the \code{m()} method will be age based). We also use Jensen's second estimator (\href{}{Kenshington, 2013}) as a scaling \code{level} model, which is based on the von Bertalanffy $K$ parameter, $M=1.5K$. 

<<jensen_second_m>>=
shape2 <- FLModelSim(model=~exp(-age-0.5))
level2 <- FLModelSim(model=~1.5*k, params=FLPar(k=0.4))
m2 <- a4aM(shape=shape2, level=level2)
m2
@ 

Note that the \code{shape} model has \code{age} as a parameter of the model but is not set using the \code{params} argument.

The \code{shape} model does not have to be age-based. For example, here we set up a \code{shape} model using Gislason's second estimator (\href{}{Kenshington, 2013}):
$M_l=K(\frac{L_{\inf}}{l})^{1.5}$. We use the default \code{level} and \class{trend} models.
% Current m() method is not ideal for length based methods as you cannot specify length range and half-widths to make compatible with FLStockLen

<<gis_shape>>=
shape_len <- FLModelSim(model=~K*(linf/len)^1.5, params=FLPar(linf=60, K=0.4))
m_len <- a4aM(shape=shape_len)
@

Another option is to model how an external factor may impact the natural mortality. This can be added through the \code{trend} model. Suppose natural mortality can be modelled with a dependency on the NAO index, due to some mechanism that results in having lower mortality when NAO is negative and higher when it's positive. In this example, the impact is represented by the NAO value on the quarter before spawning, which occurs in the second quarter. 

We use this to make a complicated natural mortality model with an age based shape model, a level model based on $K$ and a trend model driven by NAO, where mortality increases by 50\% if NAO is positive on the first quarter.

<<nao_m>>=
# Get NAO
nao.orig <- read.table("http://www.cdc.noaa.gov/data/correlation/nao.data", skip=1, nrow=62, na.strings="-99.90")
dnms <- list(quant="nao", year=1948:2009, unit="unique", season=1:12, area="unique")
# Build an FLQuant from the NAO data
nao.flq <- FLQuant(unlist(nao.orig[,-1]), dimnames=dnms, units="nao")
# Build covar by calculating mean over the first 3 months
nao <- seasonMeans(nao.flq[,,,1:3]) 
# Turn into Boolean
nao <- (nao>0)
# Constructor
trend3 <- FLModelSim(model=~1+b*nao, params=FLPar(b=0.5))
shape3 <- FLModelSim(model=~exp(-age-0.5))
level3 <- FLModelSim(model=~1.5*k, params=FLPar(k=0.4))
m3 <- a4aM(shape=shape3, level=level3, trend=trend3)
m3
@

\section{Adding uncertainty to natural mortality parameters with a multivariate normal distribution}

Uncertainty on natural mortality is added through uncertainty on the parameters.

In this section we'll' show how to add multivariate normal uncertainty. We make use of the class \class{FLModelSim} method \code{mvrnorm()}, which is a wrapper for the method \code{mvrnorm()} distributed by the package \pkg{MASS}.

We'll create an \class{a4aM} object with an exponential shape, a \code{level} model based on $k$ and temperature (Jensen's third estimator), and a \code{trend} model driven by the NAO (as above). Afterwards a variance-covariance matrix for the \code{level} and \code{trend} models will be included. Finally, create an object with 100 iterations using the \code{mvrnorm()} method.

Create the object:

<<mvrnorm_m>>=
shape4 <- FLModelSim(model=~exp(-age-0.5))
level4 <- FLModelSim(model=~k^0.66*t^0.57, params=FLPar(k=0.4, t=10), vcov=array(c(0.002, 0.01,0.01, 1), dim=c(2,2)))
trend4 <- FLModelSim(model=~1+b*nao, params=FLPar(b=0.5), vcov=matrix(0.02))
m4 <- a4aM(shape=shape4, level=level4, trend=trend4)
# Call mvrnorm()
m4 <- mvrnorm(100, m4)
m4
@

Inspect the level model (for example):

<<mvrnorm_m1>>=
m4@level
@

Note the variance in the parameters: 

<<mvrnorm_m2>>=
params(trend(m4))
@

Note the shape model has no parameters and no uncertainty:

<<mvrnorm_m3>>=
params(shape(m4))
@ 

In this particular case, the \code{shape} model will not be randomized because it doesn't have a variance-covariance matrix. Also note that because there is only one parameter in the \code{trend} model, the randomization will use a univariate normal distribution.

The same model could be achieved by using \code{mnrnorm()} on each model component:

<<univariate_m>>=
m4 <- a4aM(shape=shape4, level=mvrnorm(100, level4), trend=mvrnorm(100, trend4))
@

%Note: How to include ageing error ???

\section{Adding uncertainty to natural mortality parameters with statistical copulas}

We can also use copulas to add parameter uncertainty to the natural mortality model, similar to the way we use them for the growth model in Section \ref{sec:growth_triangle_cop}. As stated above these processes make use of the methods implemented for the \class{FLModelSim} class.

% EXPAND...

In the following example we'll use again Gislason's second estimator, $M_l=K(\frac{L_{\inf}}{l})^{1.5}$ and a triangle copula to model parameter uncertainty. The method \code{mvrtriangle()} is used to create 1000 iterations. 

<<gis_copula>>=
linf <- 60
k <- 0.4
# vcov matrix (make up some values)
mm <- matrix(NA, ncol=2, nrow=2)
# 10% cv
diag(mm) <- c((linf*0.1)^2, (k*0.1)^2)
# 0.2 correlation
mm[upper.tri(mm)] <- mm[lower.tri(mm)] <- c(0.05)
# a good way to check is using cov2cor
cov2cor(mm)
# create object
mgis2 <- FLModelSim(model=~k*(linf/len)^1.5, params=FLPar(linf=linf, k=k), vcov=mm)
# set the lower, upper and (optionally) centre of the parameters (without the centre, the triangle is symmetrical)
pars <- list(list(a=55,b=65), list(a=0.3, b=0.6, c=0.35))
mgis2 <- mvrtriangle(1000, mgis2, paramMargins=pars)
mgis2
@

The resulting parameter estimates and marginal distributions can be seen in Figure~\ref{fig:plot_tri_gis_m} and \ref{fig:plot_tri_gis_m_hist}.

<<plot_tri_gis_m, echo=FALSE, fig.cap="Parameter estimates for Gislason's second natural mortality model from using a triangle distribution.">>=
splom(t(params(mgis2)@.Data))
@

<<plot_tri_gis_m_hist, echo=FALSE, fig.cap="Marginal distributions of the parameters for Gislason's second natural mortality model using a triangle distribution.">>=
par(mfrow=c(2,1))
hist(c(params(mgis2)["linf",]), main="Linf", xlab="")
hist(c(params(mgis2)["k",]), main="K", xlab="")
@

We now have a new model that can be used for the \code{shape} model. You can use the constructor or the set method to add the new model. Note that we have a quite complex method now for M. A length based \code{shape} model from Gislason's work, Jensen's third model based on temperature \code{level} and a time \code{trend} depending on NAO. All of the component models have uncertainty in their parameters.

<<making_complicated_m>>=
m5 <- a4aM(shape=mgis2, level=level4, trend=trend4)
# or
m5 <- m4
shape(m5) <- mgis2
@

\section{Computing natural mortality time series - the "m" method}

Now that we have set up the natural mortality \class{a4aM} model and added parameter uncertainty to each component, we are ready to generate the \class{FLQuant} of natural mortality. For that we need the \code{m()} method.

The \code{m()} method is the workhorse method for computing natural mortality. The method returns an \class{FLQuant} that can be inserted in an \class{FLStock} for usage by the assessment method.

%The method uses the \code{range} slot to work out the dimensions of the \class{FLQuant} object. 
% Future developments will also allow for easy insertion into FLStockLen objects.

The size of the \class{FLQuant} object is determined by the \code{min}, \code{max}, \code{minyear} and \code{maxyear} elements of the \code{range} slot of the \class{a4aM} object. By default the values of these elements are set to 0. Giving an \class{FLQuant} with length 1 in the \code{quant} and \code{year} dimension. The \code{range} slot can be set by hand, or by using the \code{rngquant()} and \code{rngyear()} methods.

The name of the first dimension of the output \class{FLQuant} (e.g. 'age' or 'len') is determined by the parameters of the \code{shape} model. If it is not clear what the name should be then the name is set to 'quant'.

Here we demonstrate \code{m()} using the simple \class{a4aM} object we created above that has constant natural mortality.

Start with the simplest model:

<<simple_m>>=
m1
@

Check the range:

<<simple_m1>>=
range(m1)
@

Simple - no ages or years:

<<simple_m2>>=
m(m1)
@

Set the quant and year ranges:

<<simple_m3>>=
rngquant(m1) <- c(0,7)			# set the quant range
rngyear(m1) <- c(2000, 2010)	# set the year range
range(m1)
@

Create the object with the M estimates by age and year, note the name of the first dimension is 'quant'.

<<simple_m4>>=
m(m1)
@

The next example has an age-based shape. As the \code{shape} model has 'age' as a variable which is not included in the \class{FLPar} slot it is used as the name of the first dimension of the resulting \class{FLQuant}. Note that in this case the \code{mbar} values in the range become relevant. \code{mbar} the range of quants (in this case, ages) that is used to compute the mean level. This mean level will match the value given by the \code{level} model. The \code{mbar} range can be changed with the \code{rngmbar()} method. We illustrate this by making an \class{FLQuant} with age varying natural mortality. 

Check the model and set the ranges:

<<m2>>=
m2
rngquant(m2) <- c(0,7)
rngyear(m2) <- c(2000, 2003)
range(m2)
m(m2)
@

Note that the level value is:

<<m2_1>>=
predict(level(m2))
@

Which is the same as:

<<m2_2>>=
m(m2)["0"]
@

This is because the mbar range is currently set to "0" and "0" (see above) and the mean natural mortality value over this range is given by the level model. 

We can change the \code{mbar} range:

<<m2_3>>=
rngmbar(m2)<- c(0,5)
range(m2)
@

Which rescales the the natural mortality at age:

<<m2_4>>=
m(m2)
@

Check that the mortality over the mean range is the same as the level model:

<<m2_5>>=
quantMeans(m(m2)[as.character(0:5)])
@

The next example uses a time trend for the \code{trend} model. We use the \code{m3} model we made earlier. The \code{trend} model for this model has a covariate, 'nao'. This needs to be passed to the \code{m()} method. The year range of the 'nao' covariate should match that of the \code{range} slot.

Simple, pass in a single nao value (only one year):

<<m3_trend>>=
m(m3, nao=1)
@

Set ages:

<<m3_trend1>>=
rngquant(m3) <- c(0,7)
m(m3, nao=0)
@

With ages and years - passing in the NAO data as numeric (1,0,1,0)

<<m3_trend2>>=
rngyear(m3) <- c(2000, 2003)
m(m3, nao=as.numeric(nao[,as.character(2000:2003)]))
@

The final example show how \code{m()} can be used to make an \class{FLQuant} with uncertainty (see Figure~\ref{fig:uncertain_m}). We use the \code{m4} object from earlier with uncertainty on the \code{level} and \code{trend} parameters.

<<m4_uncertainty_m>>=
rngquant(m4) <- c(0,7)
rngyear(m4) <- c(2000, 2003)
flq <- m(m4, nao=as.numeric(nao[,as.character(2000:2003)]))
flq
dim(flq)
@

<<uncertain_m, echo=FALSE, fig.cap="Natural mortality with age and year trend.">>=
bwplot(data~factor(age)|year, data=flq)
@

\end{document}

